{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0d5d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-6.5.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (4.11.0)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading brotli-1.2.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (0.117.1)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-1.0.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==2.0.3 (from gradio)\n",
      "  Downloading gradio_client-2.0.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub<2.0,>=0.33.5 (from gradio)\n",
      "  Downloading huggingface_hub-1.3.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (2.2.5)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.11.6-cp312-cp312-macosx_15_0_arm64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<4.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (2.11.9)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (2025.2)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (6.0.1)\n",
      "Collecting safehttpx<0.2.0,>=0.1.7 (from gradio)\n",
      "  Downloading safehttpx-0.1.7-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (0.48.0)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (4.13.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gradio) (0.37.0)\n",
      "Collecting fsspec (from gradio-client==2.0.3->gradio)\n",
      "  Downloading fsspec-2026.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Collecting filelock (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.2)\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<4.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<4.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<=3.0,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<=3.0,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (14.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<4.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-6.5.1-py3-none-any.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-2.0.3-py3-none-any.whl (55 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-1.3.5-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.11.6-cp312-cp312-macosx_15_0_arm64.whl (134 kB)\n",
      "Downloading safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Downloading typer-0.21.1-py3-none-any.whl (47 kB)\n",
      "Downloading brotli-1.2.0-cp312-cp312-macosx_10_13_universal2.whl (861 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m861.5/861.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2026.1.0-py3-none-any.whl (201 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
      "Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: pydub, brotli, typer-slim, tomlkit, shellingham, semantic-version, orjson, hf-xet, groovy, fsspec, filelock, ffmpy, aiofiles, typer, safehttpx, huggingface-hub, gradio-client, gradio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [gradio]17/18\u001b[0m [gradio]client]b]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiofiles-24.1.0 brotli-1.2.0 ffmpy-1.0.0 filelock-3.20.3 fsspec-2026.1.0 gradio-6.5.1 gradio-client-2.0.3 groovy-0.1.2 hf-xet-1.2.0 huggingface-hub-1.3.5 orjson-3.11.6 pydub-0.25.1 safehttpx-0.1.7 semantic-version-2.10.0 shellingham-1.5.4 tomlkit-0.13.3 typer-0.21.1 typer-slim-0.21.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84518e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70461832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI Client initialized successfully.\n",
      "Base URL: http://127.0.0.1:1234/v1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")              # set in .env or env\n",
    "openai_base_url = os.getenv(\"OPENAI_BASE_URL\", \"http://127.0.0.1:1234\")\n",
    "\n",
    "openai_client = OpenAI(api_key=openai_api_key, base_url=openai_base_url)\n",
    "\n",
    "print(\"OpenAI Client initialized successfully.\")\n",
    "print(\"Base URL:\", openai_base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580de26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_markdown(text):\n",
    "    \"\"\"Display text as Markdown in Jupyter.\"\"\"\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94951345",
   "metadata": {},
   "source": [
    "Building a basic AI tutor function (no gradio yet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b068c",
   "metadata": {},
   "source": [
    "core function:\n",
    "\n",
    "1. Take a user's question as input.\n",
    "2. Construct a prompt for the OpenAI API, telling it to act as a helpful tutor.\n",
    "3. Call the OpenAI API\n",
    "4. return the AI's answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7647a484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_tutor_response(user_question):\n",
    "    \"\"\"\n",
    "    Sends a question to the OpenAI API, asking it to respond as an AI tutor.\n",
    "\n",
    "    Args:\n",
    "        user_question(str): The question asked by the user.\n",
    "\n",
    "    returns:\n",
    "        str: The AI's response, or an error message.\n",
    "\n",
    "    \"\"\"\n",
    "    system_promt = \"You are a helpful and patient AI tutor.Explain concepts clearly and provide examples when necessary.\"\n",
    "\n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "           model=\"gemma-3-1b\",\n",
    "           messages=[\n",
    "                {\"role\": \"system\", \"content\": system_promt},\n",
    "                {\"role\": \"user\", \"content\": user_question}\n",
    "                ],\n",
    "        max_tokens=512,\n",
    "        temperature=0.7,\n",
    ")\n",
    "\n",
    "        ai_response = response.choices[0].message.content\n",
    "        return ai_response\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3879f95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Asking the AI tutor: Could you explain the concept of functions in python and their purpose in programming?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "AI Tutor's Response:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Okay, let's dive into the concept of functions in Python! It’s a fundamental part of programming, and understanding them is key to writing clean and efficient code.\n",
       "\n",
       "**What is a Function in Python?**\n",
       "\n",
       "At its simplest, a function in Python is a block of code that performs a specific task.  Think of it like a mini-program within your larger program. You give the function a name, and you provide it with input (arguments) – data that’s needed for the function to work.  The function then does something with that input, and it returns a result (which is usually another value or a new value depending on the function's purpose).\n",
       "\n",
       "**Let’s break it down with an example:**\n",
       "\n",
       "```python\n",
       "def greet(name):  # This is the function definition. \n",
       "    \"\"\"This function greets a person by name.\"\"\"\n",
       "    print(f\"Hello, {name}!\")  # 'f-string' - a modern way to embed variables in strings.\n",
       "    return \"Hello!\"  # The function returns a value (in this case, the string \"Hello!\")\n",
       "\n",
       "# Calling the function\n",
       "person = greet(\"Alice\")  # Pass the argument \"Alice\" to the function.\n",
       "print(person) # Printing the returned value (which is \"Hello!\")\n",
       "```\n",
       "\n",
       "**Explanation:**\n",
       "\n",
       "*   `def greet(name):`  This line *defines* a function named `greet`. The parentheses `()` indicate that it's a function definition.  The name of the function is what you give it – `greet`.\n",
       "*   `\"\"\"This function greets a person by name.\"\"\"`:  This is a *docstring*. It's like a little note explaining what the function does.  It’s good practice to include docstrings for your code.\n",
       "*   `print(f\"Hello, {name}!\")`: This line is the *body* of the function.  It's where the action happens – it displays a greeting message.  The `f` before the string means we're using an f-string, which is a very convenient way to embed variables directly into the string.\n",
       "*   `return \"Hello!\"`:  This line *returns* a value from the function.  The `return` keyword is essential. The function will *produce* a value and pass it back to the part of the program that called the function.\n",
       "*   `person = greet"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_question = \"Could you explain the concept of functions in python and their purpose in programming?\"\n",
    "print_markdown(f\"Asking the AI tutor: {test_question}\")\n",
    "\n",
    "tutor_answer = get_ai_tutor_response(test_question)\n",
    "\n",
    "print_markdown(f\"AI Tutor's Response:\\n\")\n",
    "print_markdown(tutor_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ee64c6",
   "metadata": {},
   "source": [
    "build an interactive interface using gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a9b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e6cb523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching AI Tutor interface...\n",
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_tutor_interface_simple = gr.Interface(\n",
    "    fn=get_ai_tutor_response,\n",
    "    inputs=gr.Textbox(lines=4, label=\"Ask the AI Tutor a Question\"),\n",
    "    outputs=gr.Markdown(label=\"AI Tutor's Response\"),\n",
    "    title=\"AI Tutor\",\n",
    "    description=\"Ask programming-related questions and get explanations from the AI tutor.\",    \n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "\n",
    "print(\"Launching AI Tutor interface...\")\n",
    "ai_tutor_interface_simple.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66ae8a",
   "metadata": {},
   "source": [
    "Add Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "223f616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_ai_tutor_response(user_question):\n",
    "    \"\"\"\n",
    "    Sends a question to the OpenAI API, asking it to respond as an AI tutor, and streams the response.\n",
    "\n",
    "    Args:\n",
    "        user_question(str): The question asked by the user.\n",
    "        \n",
    "    yields:\n",
    "        str: The AI's response in chunks, or an error message.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = \"You are a helpful and patient AI tutor. Explain concepts clearly and provide examples when necessary.\"\n",
    "\n",
    "    try:\n",
    "\n",
    "        stream = openai_client.chat.completions.create(\n",
    "            model = \"gemma-3-1b\",\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_question}\n",
    "            ],\n",
    "            max_tokens = 512,\n",
    "            temperature = 0.7,\n",
    "            stream = True,\n",
    "        )\n",
    "\n",
    "        full_response = \"\" #keep track of full response if needed later\n",
    "\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
    "                text_chunk = chunk.choices[0].delta.content\n",
    "                full_response += text_chunk\n",
    "                yield full_response\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7cca2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_ai_tutor_response_with_level(user_question, explanation_level_value):\n",
    "    \"\"\"\n",
    "    Sends a question to the OpenAI API, asking it to respond as an AI tutor with a specified explanation level, and streams the response.\n",
    "\n",
    "    Args:\n",
    "        user_question (str): The question asked by the user.\n",
    "        explanation_level_value (int): The desired explanation level (1-5).\n",
    "\n",
    "    Yields:\n",
    "        str: Chunks of the AI's response (progressive).\n",
    "    \"\"\"\n",
    "    explanation_levels = {\n",
    "        1: \"like I'm five years old\",\n",
    "        2: \"like I'm 10 years old\",\n",
    "        3: \"like a high school student\",\n",
    "        4: \"like a college student\",\n",
    "        5: \"like an expert in the fields\",\n",
    "    }\n",
    "\n",
    "    level_description = explanation_levels.get(explanation_level_value, \"clearly and concisely\")\n",
    "    system_prompt = f\"You are a helpful and patient AI tutor. Explain concepts {level_description}.\"\n",
    "\n",
    "    try:\n",
    "        stream = openai_client.chat.completions.create(\n",
    "            model=\"gemma-3-1b\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_question}\n",
    "            ],\n",
    "            max_tokens=512,\n",
    "            temperature=0.7,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        full_response = \"\"\n",
    "        for chunk in stream:\n",
    "            # many local clients stream chunks with chunk.choices[0].delta.content\n",
    "            try:\n",
    "                delta = chunk.choices[0].delta\n",
    "                content = getattr(delta, \"content\", None) if delta is not None else None\n",
    "            except Exception:\n",
    "                content = None\n",
    "\n",
    "            if content:\n",
    "                full_response += content\n",
    "                yield full_response\n",
    "\n",
    "    except Exception as e:\n",
    "        yield f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "194ff4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Advanced AI Tutor interface...\n",
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_tutor_interface_simple = gr.Interface(fn = stream_ai_tutor_response_with_level,\n",
    "    inputs =[\n",
    "        gr.Textbox(lines=4, label=\"Ask the AI Tutor a Question\"),\n",
    "        gr.Slider(minimum=1, maximum=5, step=1, \n",
    "                  label=\"Explanation Level\")\n",
    "    ],\n",
    "    outputs=gr.Markdown(label=\"AI Tutor's Response(Streaming)\", container=True, height = 250),\n",
    "             title= \"Advanced AI Tutor\",\n",
    "             description=\"Ask programming-related questions and get explanations from the AI tutor.\",\n",
    "             flagging_mode=\"never\",    \n",
    "    )\n",
    "\n",
    "print(\"Launching Advanced AI Tutor interface...\")\n",
    "ai_tutor_interface_simple.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c9811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
